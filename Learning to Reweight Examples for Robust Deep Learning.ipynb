{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to Reweight Examples for Robust Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.10</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from model import *\n",
    "from data_loader import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import IPython\n",
    "import gc\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'errorbar.capsize': 5})\n",
    "import pixiedust\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'lr' : 1e-2,\n",
    "    'momentum' : 0.9,\n",
    "    'batch_size' : 128,\n",
    "    'num_iterations' : 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Following the class imbalance experiment in the paper, we used numbers 9 and 4 of the MNIST dataset to form a highly imbalanced dataset where 9 is the dominating class. The test set on the other hand is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_mnist_loader(hyperparameters['batch_size'], classes=[9, 4], proportion=0.995, mode=\"train\")\n",
    "test_loader = get_mnist_loader(hyperparameters['batch_size'], classes=[9, 4], proportion=0.5, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_var(x, requires_grad=True):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x, requires_grad=requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the validation data is small (only 10 examples) there is no need to wrap it in a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = to_var(data_loader.dataset.data_val, requires_grad=False)\n",
    "val_labels = to_var(data_loader.dataset.labels_val, requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print one batch of data to see if the train data is really imbalanced and if the test data is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([128, 1, 32, 32]), tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]))\n"
     ]
    }
   ],
   "source": [
    "for i,(img, label) in enumerate(data_loader):\n",
    "    print(img.size(),label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([128, 1, 32, 32]), tensor([ 0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,\n",
      "         1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,\n",
      "         0.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "         0.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,\n",
      "         1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,\n",
      "         1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
      "         1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
      "         1.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,\n",
      "         1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  1.,\n",
      "         0.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,\n",
      "         0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.]))\n"
     ]
    }
   ],
   "source": [
    "for i,(img, label) in enumerate(test_loader):\n",
    "    print(img.size(),label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    net = LeNet(n_out=1)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "        torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    opt = torch.optim.SGD(net.params(),lr=hyperparameters[\"lr\"])\n",
    "    \n",
    "    return net, opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "I trained a LeNet model for the MNIST data without weighting the loss as a baseline model for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, opt = build_model()\n",
    "\n",
    "net_losses = []\n",
    "plot_step = 100\n",
    "net_l = 0\n",
    "\n",
    "smoothing_alpha = 0.9\n",
    "accuracy_log = []\n",
    "for i in tqdm(range(hyperparameters['num_iterations'])):\n",
    "    net.train()\n",
    "    image, labels = next(iter(data_loader))\n",
    "\n",
    "    image = to_var(image, requires_grad=False)\n",
    "    labels = to_var(labels, requires_grad=False)\n",
    "\n",
    "    y = net(image)\n",
    "    cost = F.binary_cross_entropy_with_logits(y, labels)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    cost.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    net_l = smoothing_alpha *net_l + (1 - smoothing_alpha)* cost.item()\n",
    "    net_losses.append(net_l/(1 - smoothing_alpha**(i+1)))\n",
    "    \n",
    "    if i % plot_step == 0:\n",
    "        net.eval()\n",
    "        \n",
    "        acc = []\n",
    "        for itr,(test_img, test_label) in enumerate(test_loader):\n",
    "            test_img = to_var(test_img, requires_grad=False)\n",
    "            test_label = to_var(test_label, requires_grad=False)\n",
    "            \n",
    "            output = net(test_img)\n",
    "            predicted = (F.sigmoid(output) > 0.5).int()\n",
    "            \n",
    "            acc.append((predicted.int() == test_label.int()).float())\n",
    "\n",
    "        accuracy = torch.cat(acc,dim=0).mean()\n",
    "        accuracy_log.append(np.array([i,accuracy])[None])\n",
    "        \n",
    "        \n",
    "        IPython.display.clear_output()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(13,5))\n",
    "        ax1, ax2 = axes.ravel()\n",
    "\n",
    "        ax1.plot(net_losses, label='net_losses')\n",
    "        ax1.set_ylabel(\"Losses\")\n",
    "        ax1.set_xlabel(\"Iteration\")\n",
    "        ax1.legend()\n",
    "        \n",
    "        acc_log = np.concatenate(accuracy_log, axis=0)\n",
    "        ax2.plot(acc_log[:,0],acc_log[:,1])\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.set_xlabel('Iteration')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, due to the heavily imbalanced training data, the network could not learn how to differentiate between 9 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to Reweight Examples \n",
    "Below is a pseudocode of the method proposed in the paper. It is very straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pseudocode.PNG\" width=\"300\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "def train_lre():\n",
    "    net, opt = build_model()\n",
    "    \n",
    "    meta_losses_clean = []\n",
    "    net_losses = []\n",
    "    plot_step = 100\n",
    "\n",
    "    smoothing_alpha = 0.9\n",
    "    \n",
    "    meta_l = 0\n",
    "    net_l = 0\n",
    "    accuracy_log = []\n",
    "    for i in tqdm(range(hyperparameters['num_iterations'])):\n",
    "        net.train()\n",
    "        # Line 2 get batch of data\n",
    "        image, labels = next(iter(data_loader))\n",
    "        # since validation data is small I just fixed them instead of building an iterator\n",
    "        # initialize a dummy network for the meta learning of the weights\n",
    "        meta_net = LeNet(n_out=1)\n",
    "        meta_net.load_state_dict(net.state_dict())\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            meta_net.cuda()\n",
    "\n",
    "        image = to_var(image, requires_grad=False)\n",
    "        labels = to_var(labels, requires_grad=False)\n",
    "\n",
    "        # Lines 4 - 5 initial forward pass to compute the initial weighted loss\n",
    "        y_f_hat  = meta_net(image)\n",
    "        cost = F.binary_cross_entropy_with_logits(y_f_hat,labels, reduce=False)\n",
    "        eps = to_var(torch.zeros(cost.size()))\n",
    "        l_f_meta = torch.sum(cost * eps)\n",
    "\n",
    "        meta_net.zero_grad()\n",
    "        \n",
    "        # Line 6 perform a parameter update\n",
    "        grads = torch.autograd.grad(l_f_meta, (meta_net.params()), create_graph=True)\n",
    "        meta_net.update_params(hyperparameters['lr'], source_params=grads)\n",
    "        \n",
    "        # Line 8 - 10 2nd forward pass and getting the gradients with respect to epsilon\n",
    "        y_g_hat = meta_net(val_data)\n",
    "\n",
    "        l_g_meta = F.binary_cross_entropy_with_logits(y_g_hat,val_labels)\n",
    "\n",
    "        grad_eps = torch.autograd.grad(l_g_meta, eps, only_inputs=True)[0]\n",
    "        \n",
    "        # Line 11 computing and normalizing the weights\n",
    "        w_tilde = torch.clamp(-grad_eps,min=0)\n",
    "        norm_c = torch.sum(w_tilde)\n",
    "\n",
    "        if norm_c != 0:\n",
    "            w = w_tilde / norm_c\n",
    "        else:\n",
    "            w = w_tilde\n",
    "\n",
    "        # Lines 12 - 14 computing for the loss with the computed weights\n",
    "        # and then perform a parameter update\n",
    "        y_f_hat = net(image)\n",
    "        cost = F.binary_cross_entropy_with_logits(y_f_hat, labels, reduce=False)\n",
    "        l_f = torch.sum(cost * w)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        l_f.backward()\n",
    "        opt.step()\n",
    "\n",
    "        meta_l = smoothing_alpha *meta_l + (1 - smoothing_alpha)* l_g_meta.item()\n",
    "        meta_losses_clean.append(meta_l/(1 - smoothing_alpha**(i+1)))\n",
    "\n",
    "        net_l = smoothing_alpha *net_l + (1 - smoothing_alpha)* l_f.item()\n",
    "        net_losses.append(net_l/(1 - smoothing_alpha**(i+1)))\n",
    "\n",
    "        if i % plot_step == 0:\n",
    "            net.eval()\n",
    "\n",
    "            acc = []\n",
    "            for itr,(test_img, test_label) in enumerate(test_loader):\n",
    "                test_img = to_var(test_img, requires_grad=False)\n",
    "                test_label = to_var(test_label, requires_grad=False)\n",
    "\n",
    "                output = net(test_img)\n",
    "                predicted = (F.sigmoid(output) > 0.5).int()\n",
    "\n",
    "                acc.append((predicted.int() == test_label.int()).float())\n",
    "\n",
    "            accuracy = torch.cat(acc,dim=0).mean()\n",
    "            accuracy_log.append(np.array([i,accuracy])[None])\n",
    "\n",
    "\n",
    "            IPython.display.clear_output()\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(13,5))\n",
    "            ax1, ax2 = axes.ravel()\n",
    "\n",
    "            ax1.plot(meta_losses_clean, label='meta_losses_clean')\n",
    "            ax1.plot(net_losses, label='net_losses')\n",
    "            ax1.set_ylabel(\"Losses\")\n",
    "            ax1.set_xlabel(\"Iteration\")\n",
    "            ax1.legend()\n",
    "\n",
    "            acc_log = np.concatenate(accuracy_log, axis=0)\n",
    "            ax2.plot(acc_log[:,0],acc_log[:,1])\n",
    "            ax2.set_ylabel('Accuracy')\n",
    "            ax2.set_xlabel('Iteration')\n",
    "            plt.show()\n",
    "            \n",
    "        # return accuracy\n",
    "    return np.mean(acc_log[-6:-1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of how robust this method is with respect to the proportion of the dominant class, I varied the proportion from 0.9 to 0.995 and perform 5 runs for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxkAAAFACAYAAADQ/bHpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X+4VlWZ+P/3HWDoaGqI1oh8ZEobRQHjoJZilpMgMWmOJjqTmSVDo4VTWZRjNn6rK8NPP0yTofyR89EsRY0xEkoDtBL5ETAgKOigHqcEKVEwlaP3949nQ4+ngxxk7/Mcznm/ruu5zrPXXms/9zrHWtzPWmvvyEwkSZIkqSyva3QAkiRJkroWkwxJkiRJpTLJkCRJklQqkwxJkiRJpTLJkCRJklQqkwxJkiRJpTLJkCRJklQqkwxJkiRJpTLJkCRJklSqno0OoCPstddeuf/++zc6DEnqtObPn/9UZvZtdByN5nghSVu2LWNFt0gy9t9/f+bNm9foMCSp04qIRxsdQ2fgeCFJW7YtY4XLpSRJkiSVyiRDkiRJUqlMMiRJkiSVqlvsyZBUs3HjRpqbm3n++ecbHYoapHfv3vTr149evXo1OhRJUhdmkiF1I83Nzey2227sv//+RESjw1EHy0zWrl1Lc3MzAwYMaHQ4kqQuzOVSUjfy/PPP06dPHxOMbioi6NOnjzNZkqTKVZpkRMTIiHgwIlZGxIQt1Dk2IhZGxNKImFVXPj4ilhTl59eV/6iovzAiVkXEwir7IHU1Jhjdm39/SVJHqGy5VET0AK4E3gs0A3MjYmpmPlBXZw/gu8DIzHwsIvYuyg8BzgEOB14E7oyIOzJzZWaeVtf+/wLrquqDJEmSpG1X5UzG4cDKzHwkM18EbgJObFXnDODWzHwMIDNXF+UHAXMy87nMbAFmASfXN4za13EfBH5YYR8kSZIkbaMqk4x9gcfrjpuLsnoHAntGxMyImB8RZxblS4DhEdEnInYBRgH7tWo7HHgyM1e09eERMTYi5kXEvDVr1mx3ZyQ13sKFC5k2bdprajtz5kxGjx5dckTl23XXXRsdgiRJ263RG797AkOB9wEjgIsi4sDMXAZcCswA7gQWAi+1ans6rzKLkZmTM7MpM5v69u1bSfCSOtb2JBmSJKnjVHkL2yd45exDv6KsXjOwNjM3ABsiYjYwGHgoM68GrgaIiK8WdSmOe1JbPjW0uvClru3f/2spD/zvM6Ve8+C/fgMX//3AV62zatUqRo4cyZFHHsmvf/1rhg0bxkc+8hEuvvhiVq9ezQ033MDAgQP5xCc+wZIlS9i4cSNf+tKXOOGEE/jiF7/In/70J+69914+//nPM2DAAMaPH8/zzz/PzjvvzLXXXsvb3va2rcb5hz/8gbPPPptHHnmEXXbZhcmTJzNo0CBmzZrF+PHjgdoG6dmzZ7N+/XpOO+00nnnmGVpaWrjqqqsYPnw4M2bM4OKLL+aFF17gLW95C9deey277rorEyZMYOrUqfTs2ZPjjz+eyy67rM0YnnzyScaNG8cjjzwCwFVXXcU73/nOV9SZOHEiP/7xj3nhhRf4wAc+wL//+78DcNJJJ/H444/z/PPPM378eMaOHQvUZkHGjx/PHXfcwc4778xPfvIT9tlnn63+PiRJKluVMxlzgQMiYkBE7ASMAaa2qvMT4OiI6FksizoCWAZQtwm8P7WE4sa6dn8HLM/MZiTtcFauXMmnP/1pli9fzvLly7nxxhu59957ueyyy/jqV7/KV77yFd7znvdw//3388tf/pILLriAjRs3cskll3DaaaexcOFCTjvtNP72b/+We+65h9/+9rdccsklfOELX2jX51988cUcdthhLF68mK9+9auceWZtpeZll13GlVdeycKFC7nnnnvYeeedufHGGxkxYgQLFy5k0aJFDBkyhKeeeoovf/nL/OIXv2DBggU0NTXxjW98g7Vr13LbbbexdOlSFi9ezL/9279tMYZPfvKTvOtd72LRokUsWLCAgQNfmZzNmDGDFStWcP/997Nw4ULmz5/P7NmzAbjmmmuYP38+8+bN4/LLL2ft2rUAbNiwgSOPPJJFixZxzDHH8L3vfe+1/HkkSdpulc1kZGZLRJwHTAd6ANdk5tKIGFecn5SZyyLiTmAx8DLw/cxcUlxiSkT0ATYC52bm03WXH4MbvqXtsrUZhyoNGDCAQw89FICBAwdy3HHHEREceuihrFq1iubmZqZOnbp5FuD555/nscce+4vrrFu3jg9/+MOsWLGCiGDjxo3t+vx7772XKVOmAPCe97yHtWvX8swzz3DUUUfxqU99in/8x3/k5JNPpl+/fgwbNoyzzz6bjRs3ctJJJzFkyBBmzZrFAw88wFFHHQXAiy++yDve8Q523313evfuzUc/+lFGjx79qntA7r77bq6//noAevTowe677/6K8zNmzGDGjBkcdthhAKxfv54VK1ZwzDHHcPnll3PbbbcB8Pjjj7NixQr69OnDTjvttPkzhw4dys9//vN2/T4kSSpbpU/8zsxpwLRWZZNaHU8EJrbRdvirXPeskkKU1ACvf/3rN79/3etet/n4da97HS0tLfTo0YMpU6b8xdKnOXPmvOL4oosu4t3vfje33XYbq1at4thjj92uuCZMmMD73vc+pk2bxlFHHcX06dM55phjmD17Nj/96U8566yz+NSnPsWee+7Je9/7Xn74w7/8ruP+++/nrrvu4pZbbuGKK67g7rvvfk2xZCaf//zn+ed//udXlM+cOZNf/OIX/OY3v2GXXXbh2GOP3fxwvV69em1+DkaPHj1oaWl5TZ8tSdL2avTGb0n6CyNGjOA73/kOmQnAb3/7WwB22203nn322c311q1bx7771m5ad91117X7+sOHD+eGG24Aav9o32uvvXjDG97Aww8/zKGHHsrnPvc5hg0bxvLly3n00UfZZ599OOecc/jYxz7GggULOPLII/nVr37FypUrgdoypYceeoj169ezbt06Ro0axTe/+U0WLVq0xRiOO+44rrrqKgBeeukl1q175SN/RowYwTXXXMP69esBeOKJJ1i9ejXr1q1jzz33ZJdddmH58uXcd9997e63JEkdxSRDUqdz0UUXsXHjRgYNGsTAgQO56KKLAHj3u9/NAw88wJAhQ/jRj37EZz/7WT7/+c9z2GGHbdO39l/60peYP38+gwYNYsKECfzgBz8A4Fvf+haHHHIIgwYNolevXpxwwgnMnDmTwYMHc9hhh/GjH/2I8ePH07dvX6677jpOP/10Bg0axDve8Q6WL1/Os88+y+jRoxk0aBBHH3003/jGN7YYw7e//W1++ctfcuihhzJ06FAeeOCBV5w//vjjOeOMM3jHO97BoYceyimnnMKzzz7LyJEjaWlp4aCDDmLChAkceeSRr+E3LElStWLTN4VdWVNTU86bN6/RYUgNt2zZMg466KBGh6EGa+u/g4iYn5lNDQqp03C8kKQt25axwpkMSZIkSaWqdOO3JHW06dOn87nPfe4VZQMGDNh8N6aO9pWvfIWbb775FWWnnnoqF154YUPikSSpI5hkSOpSRowYwYgRIxodxmYXXnihCYUkqdtxuZQkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYakTu3222//iwfVtXbWWWdxyy23dFBEkiRpa7y7lNRd/WwC/P6/y73mmw6FE75W6iVvv/12Ro8ezcEHH1zqdSVJUnWcyZDUoVatWsVBBx3EOeecw8CBAzn++OP505/+xMMPP8zIkSMZOnQow4cPZ/ny5fz6179m6tSpXHDBBQwZMoSHH354q9e/6667OOywwzj00EM5++yzeeGFFwCYMGECBx98MIMGDeIzn/kMADfffDOHHHIIgwcP5phjjgHgpZde4oILLmDYsGEMGjSI//iP/wDgd7/7HccccwxDhgzhkEMO4Z577qnoNyRJ0o7PmQypuyp5xmFbrFixgh/+8Id873vf44Mf/CBTpkzh2muvZdKkSRxwwAHMmTOHf/mXf+Huu+/m/e9/P6NHj+aUU07Z6nWff/55zjrrLO666y4OPPBAzjzzTK666io+9KEPcdttt7F8+XIigqeffhqASy65hOnTp7PvvvtuLrv66qvZfffdmTt3Li+88AJHHXUUxx9/PLfeeisjRozgwgsv5KWXXuK5556r9HckSdKOzCRDUocbMGAAQ4YMAWDo0KGsWrWKX//615x66qmb62yagdgWDz74IAMGDODAAw8E4MMf/jBXXnkl5513Hr179+ajH/0oo0ePZvTo0QAcddRRnHXWWXzwgx/k5JNPBmDGjBksXrx48x6PdevWsWLFCoYNG8bZZ5/Nxo0bOemkkzbHL0mS/pJJhqQO9/rXv37z+x49evDkk0+yxx57sHDhwko+r2fPntx///3cdddd3HLLLVxxxRXcfffdTJo0iTlz5vDTn/6UoUOHMn/+fDKT73znO20+NXz27Nn89Kc/5ayzzuJTn/oUZ555ZiXxSpK0o3NPhqSGe8Mb3sCAAQO4+eabAchMFi1aBMBuu+3Gs88+267rvO1tb2PVqlWsXLkSgP/8z//kXe96F+vXr2fdunWMGjWKb37zm5uv/fDDD3PEEUdwySWX0LdvXx5//HFGjBjBVVddxcaNGwF46KGH2LBhA48++ij77LMP55xzDh/72MdYsGBB2b8GSZK6DGcyJHUKN9xwAx//+Mf58pe/zMaNGxkzZgyDBw9mzJgxnHPOOVx++eXccsstvOUtb9niNXr37s21117LqaeeSktLC8OGDWPcuHH84Q9/4MQTT+T5558nM/nGN74BwAUXXMCKFSvITI477jgGDx7MoEGDWLVqFW9/+9vJTPr27cvtt9/OzJkzmThxIr169WLXXXfl+uuv76hfjSRJO5zIzEbHULmmpqacN29eo8OQGm7ZsmUcdNBBjQ5DDdbWfwcRMT8zmxoUUqfheCFJW7YtY4XLpSRJkiSVyuVSknYY5557Lr/61a9eUTZ+/Hg+8pGPNCgiSZLUFpMMqZvJTCKi0WG8JldeeWWjQ9jhdYclspKkxnO5lNSN9O7dm7Vr1/oPzW4qM1m7di29e/dudCiSpC7OmQypG+nXrx/Nzc2sWbOm0aGoQXr37k2/fv0aHUa7RcRI4NtAD+D7mfm1VuePBX4C/E9RdGtmXhIR+wHXA/sACUzOzG93WOCS1M2ZZEjdSK9evRgwYECjw5DaJSJ6AFcC7wWagbkRMTUzH2hV9Z7MHN2qrAX4dGYuiIjdgPkR8fM22kqSKuByKUlSZ3U4sDIzH8nMF4GbgBPb0zAzf5eZC4r3zwLLgH0ri1SS9AqVJhkRMTIiHoyIlRExYQt1jo2IhRGxNCJm1ZWPj4glRfn5rdp8IiKWF+e+XmUfJEkNsy/weN1xM20nCu+MiMUR8bOIGNj6ZETsDxwGzKkiSEnSX6psuVR7prkjYg/gu8DIzHwsIvYuyg8BzqH2LdaLwJ0RcUdmroyId1P7JmtwZr6wqY0kqVtaAPTPzPURMQq4HThg08mI2BWYApyfmc+0dYGIGAuMBejfv3/1EUtSN1DlTEZ7prnPoLZJ7zGAzFxdlB8EzMnM5zKzBZgFnFyc+zjwtcx8oVUbSVLX8gSwX91xv6Jss8x8JjPXF++nAb0iYi+AiOhFLcG4ITNv3dKHZObkzGzKzKa+ffuW3QdJ6paqTDLaM819ILBnRMyMiPkRcWZRvgQYHhF9ImIXYBR/HmgOLM7NiYhZETGswj5IkhpnLnBARAyIiJ2AMcDU+goR8aYoHvwSEYdTG9fWFmVXA8sy8xsdHLckdXuNvrtUT2AocBywM/CbiLgvM5dFxKXADGADsBB4qa7NG4EjgWHAjyPib7LVjf+d/pakHVtmtkTEecB0arewvSYzl0bEuOL8JOAU4OMR0QL8CRiTmRkRRwMfAv47IhYWl/xCMdshSapYlUnGVqe5qc1urM3MDcCGiJgNDAYeysyrqX0LRUR8tai7qc2tRVJxf0S8DOwFvOLG/5k5GZgM0NTU5JPHJGkHVCQF01qVTap7fwVwRRvt7gV2zEfbS1IXUOVyqa1Oc1N7gNLREdGzWBZ1BLXbDFK3Cbw/tf0YNxZtbgfeXZw7ENgJeKrCfkiSJEnaBpXNZLRnmrtYFnUnsBh4mdrTXJcUl5gSEX2AjcC5mfl0UX4NcE1ELKF256kPt14qJUmSJKlxKt2TsbVp7uJ4IjCxjbbDt3DNF4F/KjFMSZIkSSXyid+SJEmSSmWSIUmSJKlUJhmSJEmSSmWSIUmSJKlUJhmSJEmSSmWSIUmSJKlUJhmSJEmSSmWSIUmSJKlUJhmSJEmSSmWSIUmSJKlUJhmSJEmSSmWSIUmSJKlUJhmSJEmSSmWSIUmSJKlUJhmSJEmSSmWSIUmSJKlUJhmSJEmSSmWSIUmSJKlUJhmSJEmSSmWSIUmSJKlUJhmSJEmSSmWSIUmSJKlUJhmSJEmSSmWSIUmSJKlUJhmSJEmSSmWSIUmSJKlUJhmSJEmSSlVpkhERIyPiwYhYGRETtlDn2IhYGBFLI2JWXfn4iFhSlJ9fV/6liHiiaLMwIkZV2QdJkiRJ26ZnVReOiB7AlcB7gWZgbkRMzcwH6ursAXwXGJmZj0XE3kX5IcA5wOHAi8CdEXFHZq4smn4zMy+rKnZJkiRJr12VMxmHAysz85HMfBG4CTixVZ0zgFsz8zGAzFxdlB8EzMnM5zKzBZgFnFxhrJIkSZJKUmWSsS/weN1xc1FW70Bgz4iYGRHzI+LMonwJMDwi+kTELsAoYL+6dp+IiMURcU1E7NnWh0fE2IiYFxHz1qxZU06PJEmSJG1Vozd+9wSGAu8DRgAXRcSBmbkMuBSYAdwJLAReKtpcBfwNMAT4HfB/27pwZk7OzKbMbOrbt2+1vZAkSZK0WZVJxhO8cvahX1FWrxmYnpkbMvMpYDYwGCAzr87MoZl5DPBH4KGi/MnMfCkzXwa+R21ZliRJkqROosokYy5wQEQMiIidgDHA1FZ1fgIcHRE9i2VRRwDLAOo2gfenth/jxuL4zXXtP0BtaZUkSZKkTqKyu0tlZktEnAdMB3oA12Tm0ogYV5yflJnLIuJOYDHwMvD9zNyUNEyJiD7ARuDczHy6KP96RAwBElgF/HNVfZAkSZK07SpLMgAycxowrVXZpFbHE4GJbbQdvoVrfqjMGCVJkiSVq9EbvyVJkiR1MSYZkqROKyJGRsSDEbEyIia0cf7YiFgXEQuL1xfrzl0TEasjwr17ktTBTDIkSZ1SRPQArgROAA4GTo+Ig9uoek9mDilel9SVXweMrD5SSVJrJhmSpM7qcGBlZj6SmS8CNwEntrdxZs4G/lBVcJKkLTPJkCR1VvsCj9cdNxdlrb0zIhZHxM8iYmDHhCZJejWV3l1KkqSKLQD6Z+b6iBgF3A4csC0XiIixwFiA/v37lx+hJHVDzmRIkjqrJ4D96o77FWWbZeYzmbm+eD8N6BURe23Lh2Tm5Mxsysymvn37bm/MkiRMMiRJnddc4ICIGBAROwFjgKn1FSLiTRERxfvDqY1razs8UknSK5hkSJI6pcxsAc4DpgPLgB9n5tKIGBcR44pqpwBLImIRcDkwJjMTICJ+CPwGeFtENEfERzu+F5LUPbknQ5LUaRVLoKa1KptU9/4K4IottD292ugkSVviTIYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSpVpUlGRIyMiAcjYmVETNhCnWMjYmFELI2IWXXl4yNiSVF+fhvtPh0RGRF7VdkHSZIkSdumZ1UXjogewJXAe4FmYG5ETM3MB+rq7AF8FxiZmY9FxN5F+SHAOcDhwIvAnRFxR2auLM7vBxwPPFZV/JIkSZJemypnMg4HVmbmI5n5InATcGKrOmcAt2bmYwCZubooPwiYk5nPZWYLMAs4ua7dN4HPAllh/JKkEkTEJyJiz0bHIUnqOFUmGfsCj9cdNxdl9Q4E9oyImRExPyLOLMqXAMMjok9E7AKMAvYDiIgTgScyc1GFsUuSyrMPtdnsHxfLaKPRAUmSqlXZcqlt+PyhwHHAzsBvIuK+zFwWEZcCM4ANwELgpSLh+AK1pVKvKiLGAmMB+vfvX1H4kqStycx/i4iLqP1/90eAKyLix8DVmflwY6OTJFWhypmMJyhmHwr9irJ6zcD0zNyQmU8Bs4HBAJl5dWYOzcxjgD8CDwFvAQYAiyJiVXHNBRHxptYfnpmTM7MpM5v69u1bctckSdsiMxP4ffFqAfYEbomIrzc0MElSJapMMuYCB0TEgIjYCRgDTG1V5yfA0RHRs5ilOAJYBlC3Cbw/tf0YN2bmf2fm3pm5f2buTy1JeXtm/r7CfkiStkNxt8D5wNeBXwGHZubHqc1k/0NDg5MkVaKy5VKZ2RIR5wHTgR7ANZm5NCLGFecnFcui7gQWAy8D38/MJcUlpkREH2AjcG5mPl1VrJKkSr0RODkzH60vzMyXI2J0g2KSJFWoXUlGRIwHrgWeBb4PHAZMyMwZr9YuM6cB01qVTWp1PBGY2Ebb4VuLq5jNkCR1bj8D/rDpICLeAByUmXMyc1njwpIkVaW9y6XOzsxnqG3a2xP4EPC1yqKSJHUlVwHr647XF2WSpC6qvUnGptsNjgL+MzOX1pVJkvRqotj4DdSWSdH4uxtKkirU3iRjfkTMoJZkTI+I3ajtoZAkaWseiYhPRkSv4jUeeKTRQUmSqtPeJOOjwARgWGY+B+xE7V7nkiRtzTjgndRuY95M7U6CYxsakSSpUu2drk7gYGA0cAnwV0DvqoKSJHUdmbma2m3MJUndRHuTjO9SWx71HmpJxrPAFGBYRXFJkrqIiOhNbUZ8IHVfUGXm2Q0LSpJUqfYulzoiM88FngfIzD9SWzIlSdLW/CfwJmAEMAvoR+3LKklSF9XeJGNjRPSgtmyKiOiLG78lSe3z1sy8CNiQmT8A3kdtX4YkqYtqb5JxOXAbsHdEfAW4F/hqZVFJkrqSjcXPpyPiEGB3YO8GxiNJqli79mRk5g0RMR84jtrzMU7yKa2SpHaaHBF7Av8GTAV2BS5qbEiSpCq1K8mIiLcA/5OZV0bEscB7I+J3mfl0pdFJknZoEfE64JliL99s4G8aHJIkqQO0d7nUFOCliHgr8B/AfsCNlUUlSeoSiqd7f7bRcUiSOlZ7k4yXM7MFOBm4IjMvAN5cXViSpC7kFxHxmYjYLyLeuOnV6KAkSdVp73MyNkbE6cCZwN8XZb2qCUmS1MWcVvw8t64scemUJHVZ7U0yPgKMA76Smf8TEQOo3fdckqRXlZkDGh2DJKljtffuUg8AnwQo7hCyW2ZeWmVgkqSuISLObKs8M6/v6FgkSR2jXXsyImJmRLyhWEO7APheRHyj2tAkSV3EsLrXcOBLwPvb0zAiRkbEgxGxMiImtHH+2IhYFxELi9cX29tWklSd9i6X2j0zn4mIjwHXZ+bFEbG4ysAkSV1DZn6i/jgi9gBu2lq7iOgBXAm8F2gG5kbE1GJ2vd49mTn6NbaVJFWgvXeX6hkRbwY+CNxRYTySpK5vA9CefRqHAysz85HMfJFaYnJiOz9je9pKkrZTe2cyLgGmA7/KzLkR8TfAiurCkiR1FRHxX9TuJgW1L7cOBn7cjqb7Ao/XHTcDR7RR753F7PoTwGcyc+k2tCUixgJjAfr379+OsCRJW9Pejd83AzfXHT8C/ENVQUmSupTL6t63AI9mZnNJ114A9M/M9RExCrgdOGBbLpCZk4HJAE1NTbmV6pKkdmjvxu9+EXFbRKwuXlMiol/VwUmSuoTHgDmZOSszfwWsjYj929HuCWC/uuN+RdlmmflMZq4v3k8DekXEXu1pK0mqTnv3ZFwLTAX+unj9V1EmSdLW3Ay8XHf8EnWz469iLnBARAyIiJ2AMdTGos0i4k0REcX7w6mNa2vb01aSVJ327snom5n1ScV1EXF+FQFJkrqcnsXmawAy88XiH/6vKjNbIuI8ansCewDXZObSiBhXnJ8EnAJ8PCJagD8BYzIzgTbblt4zSVKb2ptkrI2IfwJ+WByfTu2bIkmStmZNRLw/M6cCRMSJwFPtaVgsgZrWqmxS3fsrgCva21aS1DHam2ScDXwH+Ca1O4T8GjiropgkSV3LOOCGiNiUDDQDbT4FXJLUNbT37lKP0urprMVyqW9VEZQkqevIzIeBIyNi1+J4fYNDkiRVrL0bv9vyqa1ViIiREfFgRKyMiAlbqHNsRCyMiKURMauufHxELCnKz68r//8iYnHRZkZE/PV29EGSVLGI+GpE7JGZ64tbze4ZEV9udFySpOpsT5IRr3oyogdwJXACtQcvnR4RB7eqswfwXeD9mTkQOLUoPwQ4h9oTWwcDoyPirUWziZk5KDOHUHv6+Be3ow+SpOqdkJlPbzrIzD8CoxoYjySpYtuTZGztgUWHAysz85HiriI3ASe2qnMGcGtmPgaQmauL8oOo3VP9ucxsAWYBJxd1nqlr/1ftiEOS1Fg9IuL1mw4iYmfg9a9SX5K0g3vVPRkR8Sxt/yM+gJ23cu19gcfrjpuBI1rVOZDag5NmArsB387M64ElwFciog+1WxKOAubVxfUVapsG1wHv3kLsY4GxAP37999KqJKkCt0A3BUR11IbP84CftDQiCRJlXrVJCMzd+uAzx8KHEctaflNRNyXmcsi4lJgBrABWEjt4U2b4roQuDAiPg+cB1zcRuyTgckATU1NznZIUoNk5qURsQj4O2pfXE0H/k9jo5IkVWl7lkttzRPAfnXH/Yqyes3A9MzckJlPAbOp7cEgM6/OzKGZeQzwR+ChNj7jBuAfSo9cklS2J6klGKcC7wGWNTYcSVKVqkwy5gIHRMSA4smuY4Cprer8BDg6InpGxC7UllMtA4iIvYuf/antx7ixOD6grv2JwPIK+yBJeo0i4sCIuDgillN71tJjQGTmu4uH6EmSuqj2Poxvm2VmS0ScR20bY1Z+AAAR4UlEQVRavAdwTWYujYhxxflJxbKoO4HFwMvA9zNzSXGJKcWejI3AuXV3JvlaRLytqP8otYc8SZI6n+XAPcDozFwJEBH/2tiQJEkdobIkAyAzpwHTWpVNanU8EZjYRtvhW7imy6MkacdwMrVZ7F8WXyjdxFZufy5J6hqqXC4lSerGMvP2zBwD/C3wS+B8YO+IuCoijm9sdJKkKplkSJIqVdzc48bM/HtqNwH5LfC5BoclSaqQSYYkqcNk5h8zc3JmHtfoWCRJ1THJkCRJklQqkwxJkiRJpTLJkCRJklQqkwxJkiRJpTLJkCRJklQqkwxJkiRJpTLJkCRJklQqkwxJkiRJpTLJkCRJklQqkwxJkiRJpTLJkCRJklQqkwxJkiRJpTLJkCRJklQqkwxJkiRJpTLJkCRJklQqkwxJkiRJpTLJkCRJklQqkwxJkiRJpTLJkCRJklQqkwxJkiRJpTLJkCRJklQqkwxJkiRJpTLJkCRJklSqSpOMiBgZEQ9GxMqImLCFOsdGxMKIWBoRs+rKx0fEkqL8/LryiRGxPCIWR8RtEbFHlX2QJEmStG0qSzIiogdwJXACcDBwekQc3KrOHsB3gfdn5kDg1KL8EOAc4HBgMDA6It5aNPs5cEhmDgIeAj5fVR8kSZIkbbsqZzIOB1Zm5iOZ+SJwE3BiqzpnALdm5mMAmbm6KD8ImJOZz2VmCzALOLmoM6MoA7gP6FdhHyRJkiRtoyqTjH2Bx+uOm4uyegcCe0bEzIiYHxFnFuVLgOER0ScidgFGAfu18RlnAz8rOW5JUifRnmW3Rb1hEdESEafUlbW57FaSVL2eneDzhwLHATsDv4mI+zJzWURcCswANgALgZfqG0bEhUALcENbF46IscBYgP79+1fWAUlSNeqW3b6X2hdVcyNiamY+0Ea9TWPGprL6ZbcvAndGxB2ZubKj4pek7qzKmYwneOXsQ7+irF4zMD0zN2TmU8BsanswyMyrM3NoZh4D/JHa/gsAIuIsYDTwj5mZbX14Zk7OzKbMbOrbt29ZfZIkdZz2LLsF+AQwBVhdV7bFZbeSpOpVmWTMBQ6IiAERsRMwBpjaqs5PgKMjomexLOoIYBlAROxd/OxPbWC4sTgeCXyW2mbx5yqMX5LUWFtddhsR+wIfAK5q1ba9y26JiLERMS8i5q1Zs6a04CWpO6tsuVRmtkTEecB0oAdwTWYujYhxxflJxbKoO4HFwMvA9zNzSXGJKRHRB9gInJuZTxflVwCvB34eEQD3Zea4qvohSerUvgV8LjNfLsYEANqz7Lau7mRgMkBTU1Obs+OSpG1T6Z6MzJwGTGtVNqnV8URgYhtth2/hmm9tq1yS1OW0Z9ltE3BTkWDsBYyKiJbMvD0zrwauBoiIr1KbCZEkdYBGb/yWJGlLNi+7pZZcjKF26/PNMnPApvcRcR1wR2beXhzvnZmr65bdHtlRgUtSd2eSIUnqlNqz7HYrl9jSsltJUsVMMiRJnVZ7lt3WlZ/V6rjNZbeSpOpVeXcpSZIkSd2QSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUplkSJIkSSqVSYYkSZKkUlWaZETEyIh4MCJWRsSELdQ5NiIWRsTSiJhVVz4+IpYU5efXlZ9alL0cEU1Vxi9JkiRp21WWZERED+BK4ATgYOD0iDi4VZ09gO8C78/MgcCpRfkhwDnA4cBgYHREvLVotgQ4GZhdVeySJEmSXrsqZzIOB1Zm5iOZ+SJwE3BiqzpnALdm5mMAmbm6KD8ImJOZz2VmCzCLWmJBZi7LzAcrjFuSJEnSdqgyydgXeLzuuLkoq3cgsGdEzIyI+RFxZlG+BBgeEX0iYhdgFLDftnx4RIyNiHkRMW/NmjWvsQuSJEmStlXPTvD5Q4HjgJ2B30TEfZm5LCIuBWYAG4CFwEvbcuHMnAxMBmhqaspSo5YkSZK0RVXOZDzBK2cf+hVl9ZqB6Zm5ITOforbPYjBAZl6dmUMz8xjgj8BDFcYqSZIkqSRVJhlzgQMiYkBE7ASMAaa2qvMT4OiI6FksizoCWAYQEXsXP/tT249xY4WxSpIkSSpJZculMrMlIs4DpgM9gGsyc2lEjCvOTyqWRd0JLAZeBr6fmUuKS0yJiD7ARuDczHwaICI+AHwH6Av8NCIWZuaIqvohSZIkadtUuicjM6cB01qVTWp1PBGY2Ebb4Vu45m3AbSWGKUmSJKlEPvFbkiRJUqlMMiRJkiSVyiRDkiRJUqlMMiRJkiSVyiRDkiRJUqlMMiRJkiSVyiRDkiRJUqlMMiRJnVZEjIyIByNiZURMeJV6wyKiJSJOqSv714hYGhFLIuKHEdG7Y6KWJJlkSJI6pYjoAVwJnAAcDJweEQdvod6lwIy6sn2BTwJNmXkI0AMY0xFxS5JMMiRJndfhwMrMfCQzXwRuAk5so94ngCnA6lblPYGdI6InsAvwv1UGK0n6M5MMSVJntS/weN1xc1G2WTFj8QHgqvryzHwCuAx4DPgdsC4zZyBJ6hAmGZKkHdm3gM9l5sv1hRGxJ7VZjwHAXwN/FRH/1NYFImJsRMyLiHlr1qypPGBJ6g56NjoASZK24Algv7rjfkVZvSbgpogA2AsYFREtQC/gfzJzDUBE3Aq8E/h/rT8kMycDkwGampqy5D5IUrdkkiFJ6qzmAgdExABqycUY4Iz6Cpk5YNP7iLgOuCMzb4+II4AjI2IX4E/AccC8jgpckro7kwxJUqeUmS0RcR4wndrdoa7JzKURMa44P+lV2s6JiFuABUAL8FuK2QpJUvVMMiRJnVZmTgOmtSprM7nIzLNaHV8MXFxZcJKkLXLjtyRJkqRSmWRIkiRJKpVJhiRJkqRSmWRIkiRJKpVJhiRJkqRSmWRIkiRJKpVJhiRJkqRSmWRIkiRJKpVJhiRJkqRSmWRIkiRJKlWlSUZEjIyIByNiZURM2EKdYyNiYUQsjYhZdeXjI2JJUX5+XfkbI+LnEbGi+LlnlX2QJEmStG0qSzIiogdwJXACcDBwekQc3KrOHsB3gfdn5kDg1KL8EOAc4HBgMDA6It5aNJsA3JWZBwB3FceSJEmSOokqZzIOB1Zm5iOZ+SJwE3BiqzpnALdm5mMAmbm6KD8ImJOZz2VmCzALOLk4dyLwg+L9D4CTKuyDJEmSpG1UZZKxL/B43XFzUVbvQGDPiJgZEfMj4syifAkwPCL6RMQuwChgv+LcPpn5u+L974F92vrwiBgbEfMiYt6aNWvK6I8kSZKkdujZCT5/KHAcsDPwm4i4LzOXRcSlwAxgA7AQeKl148zMiMi2LpyZk4HJAE1NTW3WkSRJklS+KmcynuDPsw8A/Yqyes3A9MzckJlPAbOp7cEgM6/OzKGZeQzwR+Chos2TEfFmgOLnaiRJkiR1GlUmGXOBAyJiQETsBIwBpraq8xPg6IjoWSyLOgJYBhARexc/+1Pbj3Fj0WYq8OHi/YeLa0iSJEnqJCpbLpWZLRFxHjAd6AFck5lLI2JccX5SsSzqTmAx8DLw/cxcUlxiSkT0ATYC52bm00X514AfR8RHgUeBD1bVB0mSJEnbrtI9GZk5DZjWqmxSq+OJwMQ22g7fwjXXUtvDIUmSJKkT8onfkiRJkkplkiFJkiSpVCYZkiRJkkplkiFJkiSpVCYZkiRJkkplkiFJkiSpVCYZkiRJkkoVmdnoGCoXEWuoPbhvR7IX8FSjg+hA9rdrs7+d3//JzL6NDqLRHC92CN2pv92pr2B/dwTtHiu6RZKxI4qIeZnZ1Og4Oor97drsr1Sd7vbfW3fqb3fqK9jfrsblUpIkSZJKZZIhSZIkqVQmGZ3X5EYH0MHsb9dmf6XqdLf/3rpTf7tTX8H+dinuyZAkSZJUKmcyJEmSJJXKJEOSJElSqUwyGigi3hgRP4+IFcXPPbdQb2REPBgRKyNiQhvnPx0RGRF7VR/1a7e9/Y2IiRGxPCIWR8RtEbFHx0XfPu34W0VEXF6cXxwRb29v287otfY3IvaLiF9GxAMRsTQixnd89Ntue/6+xfkeEfHbiLij46LWjs6xouuNFeB40cZ5x4tXnt/xx4vM9NWgF/B1YELxfgJwaRt1egAPA38D7AQsAg6uO78fMJ3aw6P2anSfquwvcDzQs3h/aVvtG9y/V/1bFXVGAT8DAjgSmNPetp3ttZ39fTPw9uL9bsBDXbm/dec/BdwI3NHo/vjacV6OFV1rrGjP36uo43iRjhc78njhTEZjnQj8oHj/A+CkNuocDqzMzEcy80XgpqLdJt8EPgvsCDv4t6u/mTkjM1uKevcB/SqOd1tt7W9FcXx91twH7BERb25n287mNfc3M3+XmQsAMvNZYBmwb0cG/xpsz9+XiOgHvA/4fkcGrS7BseIv7chjBTheOF50g/HCJKOx9snM3xXvfw/s00adfYHH646bizIi4kTgicxcVGmU5dmu/rZyNrVvADqT9sS+pTrt7Xdnsj393Swi9gcOA+aUHmG5tre/36L2j7yXqwpQXZZjxV/akccKcLxwvOgG40XPRgfQ1UXEL4A3tXHqwvqDzMyIaPc3TBGxC/AFatPCnUZV/W31GRcCLcANr6W9Oo+I2BWYApyfmc80Op6qRMRoYHVmzo+IYxsdjzofx4rNHCvUJseLHY9JRsUy8++2dC4intw0FVhMka1uo9oT1NbSbtKvKHsLMABYFBGbyhdExOGZ+fvSOrCNKuzvpmucBYwGjsvMzjbt/6qxb6VOr3a07Wy2p79ERC9qA8YNmXlrhXGWZXv6+w/A+yNiFNAbeENE/L/M/KcK49UOxLHiz7rBWAGOF44X3WG86OhNIL7+/AIm8srNbV9vo05P4BFqg8SmzUMD26i3is6/mW+7+guMBB4A+ja6L1vo31b/VtTWWNZv9Lp/W/7Onem1nf0N4HrgW43uR0f0t1WdY9mBN/L56viXY0XXGiva+/dyvHC82NHHi4YH0J1fQB/gLmAF8AvgjUX5XwPT6uqNonY3hYeBC7dwrR1h4Niu/gIrqa1fXFi8JjW6T2308S9iB8YB44r3AVxZnP9voGlb/s6d7fVa+wscTW0D6uK6v+eoRvenyr9v3TV26EHDV8e/HCu63lixpfgdLxwvWl1jhx4vouiEJEmSJJXCu0tJkiRJKpVJhiRJkqRSmWRIkiRJKpVJhiRJkqRSmWRIkiRJKpVJhtQOEbG++Ll/RJxR8rW/0Or412VeX5LUMRwrpD8zyZC2zf7ANg0cEdFzK1VeMXBk5ju3MSZJUueyP44V6uZMMqRt8zVgeEQsjIh/jYgeETExIuZGxOKI+GeAiDg2Iu6JiKnUnjxLRNweEfMjYmlEjC3KvgbsXFzvhqJs0zdhUVx7SUT8d0ScVnftmRFxS0Qsj4gbIiIa8LuQJLXNsULd3tayZkmvNAH4TGaOBigGgHWZOSwiXg/8KiJmFHXfDhySmf9THJ+dmX+IiJ2BuRExJTMnRMR5mTmkjc86GRgCDAb2KtrMLs4dBgwE/hf4FXAUcG/53ZUkvQaOFer2nMmQts/xwJkRsRCYA/QBDijO3V83aAB8MiIWAfcB+9XV25KjgR9m5kuZ+SQwCxhWd+3mzHwZWEhtal6S1Dk5VqjbcSZD2j4BfCIzp7+iMOJYYEOr478D3pGZz0XETKD3dnzuC3XvX8L/LUtSZ+ZYoW7HmQxp2zwL7FZ3PB34eET0AoiIAyPir9potzvwx2LQ+FvgyLpzGze1b+Ue4LRiLW9f4Bjg/lJ6IUmqkmOFuj0zWmnbLAZeKqayrwO+TW36eUGxoW4NcFIb7e4ExkXEMuBBatPgm0wGFkfEgsz8x7ry24B3AIuABD6bmb8vBh5JUuflWKFuLzKz0TFIkiRJ6kJcLiVJkiSpVCYZkiRJkkplkiFJkiSpVCYZkiRJkkplkiFJkiSpVCYZkiRJkkplkiFJkiSpVP8/db3hHDG2vgUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1d7fc9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%pixie_debugger\n",
    "num_repeats = 5\n",
    "proportions = [0.95]\n",
    "accuracy_log = {}\n",
    "\n",
    "for prop in proportions:\n",
    "    data_loader = get_mnist_loader(hyperparameters['batch_size'], classes=[9, 4], proportion=prop, mode=\"train\")\n",
    "    val_data = to_var(data_loader.dataset.data_val, requires_grad=False)\n",
    "    val_labels = to_var(data_loader.dataset.labels_val, requires_grad=False)\n",
    "    \n",
    "    for k in range(num_repeats):\n",
    "        accuracy = train_lre()\n",
    "        \n",
    "        if prop in accuracy_log:\n",
    "            accuracy_log[prop].append(accuracy)\n",
    "        else:\n",
    "            accuracy_log[prop] = [accuracy]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for prop in proportions:\n",
    "    accuracies = accuracy_log[prop]\n",
    "    plt.scatter([prop] * len(accuracies), accuracies)\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(accuracy_log.items())])\n",
    "accuracies_std = np.array([np.std(v) for k,v in sorted(accuracy_log.items())])\n",
    "plt.errorbar(proportions, accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Performance on varying class proportions')\n",
    "plt.xlabel('proportions')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even at 0.995 proportion of the dominant class in the training data, the model still reaches 90+% accuracy on the balanced test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
